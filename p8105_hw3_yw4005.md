P8105 HW3
================
Yijin Serena Wang
2022-10-15

``` r
library(tidyverse)
library(readxl)
library(janitor)
library(lubridate)
library(ggplot2)
library(p8105.datasets)
library(patchwork)
library(ggridges)
data("ny_noaa")
data("instacart")
```

``` r
knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

The `instacart` data set contains users’ online purchasing information
in 2017. It has 1384617 rows and 15 columns. The dataset is organized by
`order_id` and `product_id` of each user. It also has detailed
information for each order such as `order_dow`,
`days_since_prior_order`.

``` r
aisle_product_count <- instacart %>%
  select(aisle, product_id) %>%
  group_by(aisle) %>%
  # calculate count
  summarize(product_count = n()) %>%
  arrange(desc(product_count))
```

There are 134 aisles. Fresh vegetables has the most items ordered.

``` r
aisle_product_count %>%
  # filter data
  filter(product_count > 10000) %>%
  # create plot
  ggplot(aes(x = reorder(aisle,-product_count), y = product_count)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  # add labels
  labs(x = "Aisle", y = "Number of items ordered")
```

<img src="p8105_hw3_yw4005_files/figure-gfm/aisle product plot-1.png" width="90%" />

``` r
instacart %>%
  # filter data
  filter(aisle %in% c(
    "baking ingredients",
    "dog food care",
    "packaged vegetables fruits"
  )) %>%
  select(aisle, product_name) %>%
  group_by(aisle, product_name) %>%
  # calculate count
  summarise(product_count = n()) %>%
  # get top 3
  top_n(3, product_count) %>%
  ungroup() %>%
  knitr::kable(digits = 1)
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the
    ## `.groups` argument.

| aisle                      | product_name                                  | product_count |
|:---------------------------|:----------------------------------------------|--------------:|
| baking ingredients         | Cane Sugar                                    |           336 |
| baking ingredients         | Light Brown Sugar                             |           499 |
| baking ingredients         | Pure Baking Soda                              |           387 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |            28 |
| dog food care              | Small Dog Biscuits                            |            26 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |            30 |
| packaged vegetables fruits | Organic Baby Spinach                          |          9784 |
| packaged vegetables fruits | Organic Blueberries                           |          4966 |
| packaged vegetables fruits | Organic Raspberries                           |          5546 |

``` r
instacart %>%
  # filter data
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream"))  %>%
  select(order_hour_of_day, order_dow, product_name) %>%
  group_by(product_name, order_dow) %>%
  # calculate mean
  summarise(mean_order_hour = mean(order_hour_of_day)) %>%
  ungroup()  %>%
  # pivot to a table
  pivot_wider(names_from = product_name,
              values_from = mean_order_hour) %>%
  knitr::kable(digits = 1)
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

| order_dow | Coffee Ice Cream | Pink Lady Apples |
|----------:|-----------------:|-----------------:|
|         0 |             13.8 |             13.4 |
|         1 |             14.3 |             11.4 |
|         2 |             15.4 |             11.7 |
|         3 |             15.3 |             14.2 |
|         4 |             15.2 |             11.6 |
|         5 |             12.3 |             12.8 |
|         6 |             13.8 |             11.9 |

# Problem 2

``` r
# load and clean accelerometers data set
accel_data <- read_csv("./Data/accel_data.csv") %>%
  # clean names
  clean_names() %>%
  # pivot activity_* columns longer
  # minute column has the minute number associated with activity
  # activity column has corresponding values to the original activity.* columns
  pivot_longer(
    cols = starts_with("activity_"),
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity"
  ) %>%
  mutate(
    # create a column to denote if the day value is weekday or weekend
    day_type = ifelse(day %in% c("Saturday", "Sunday"),
                             "weekend",
                             "weekday"),
    # make day factors for calculating total activities later
    day = factor(
      day,
      levels = c(
        "Monday",
        "Tuesday",
        "Wednesday",
        "Thursday",
        "Friday",
        "Saturday",
        "Sunday"
      )
    ),
    # convert minute to numbers
    minute = as.integer(minute))
```

    ## Rows: 35 Columns: 1443
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The resulting data set has 50400 rows and 6 columns. It contains week,
day_id, day, minute, activity, day_type columns. It contains 5 weeks of
data of an accelerometer worn by a patient. The data is documented at
each minute interval in 24 hours for each day.

``` r
accel_data %>%
  group_by(day) %>%
  # calculate total activity
  summarise(total_activity = sum(activity)) %>%
  knitr::kable(digits = 1)
```

| day       | total_activity |
|:----------|---------------:|
| Monday    |        1858699 |
| Tuesday   |        1799238 |
| Wednesday |        2129772 |
| Thursday  |        2091151 |
| Friday    |        2291711 |
| Saturday  |        1369237 |
| Sunday    |        1919213 |

There are more activities from Wednesday to Friday. Other days of the
week have similar amount of activities.

``` r
# create plot
ggplot(data = accel_data,
  aes(x = minute, y = activity, color = day)) +
  geom_line(alpha = .3) +
  # rotate x-axis labels
  theme(axis.text.x = element_text(
    angle = 90,
    vjust = 0.5,
    hjust = 1
  )) +
  # add title
  labs(title = "24-hour activity time courses") + 
  # move legend to the right
  theme(legend.position = "right")
```

<img src="p8105_hw3_yw4005_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

Assume min 1 is midnight. It seems for every day in a week, there is a
specific period of time (might be mornings) that has low activity. At
other times of the day, there is a day-effect on the time that the
participant did activity. There a cluster of yellow line for Sundays at
centered at a period of time and some clusters for days in the early
part of the week. In general, the participant did more activity in
very-early morning and evenings on of weekdays, more activity in the
late morning and afternoon at weekends.

# Problem 3

``` r
clean_ny_noaa <- ny_noaa %>%
  # clean names
  clean_names() %>%
  # break date column into month, day, year columns
  separate(col = date,
           sep = "-",
           into = c("year", "month", "day")) %>%
  # convert precipitation to mm, temperatures to degree Celcius
  # and snow depth to cm
  mutate(
    prcp = prcp / 10,
    snwd = snwd / 10,
    tmax = as.numeric(tmax) / 10,
    tmin = as.numeric(tmin) / 10
  )
```

The `ny_noaa` data set has 2595176 rows and 7 columns. It contains
precipitation, snowfall, depth of snow and min and max temperatures of
each documented NY state weather stations from 1981-01-01 and
2010-12-31. Just by looking at the data, there are a lot of cells with
NAs. Sometimes, there is no information about precipitation, snowfall,
depth of snow and min and max temperatures for a particular station and
a date. min and max temperatures are missing for a lot of stations and
dates.

The cleaned data set has 2595176 rows and 9 columns.

``` r
clean_ny_noaa %>%
  # count values
  count(snow, name = "count") %>%
  # take the top one
  top_n(1, count) %>%
  knitr::kable(digits = 1)
```

| snow |   count |
|-----:|--------:|
|    0 | 2008508 |

The most commonly observed value is 0. It might be because the actual
data is documented in the `snwd` column. Or it could also be another way
for documenting missing values, instead of using NAs.

``` r
clean_ny_noaa  %>%
  # filter data
  filter(month %in% c("01", "07"))  %>%
  group_by(year, month, id) %>%
  # calculate average of max temperatures for observations in each station in each month, year
  summarize(avg_tmax = mean(tmax, na.rm = TRUE)) %>%
  ungroup() %>%
  # make plot
  ggplot(aes(x = year, y = avg_tmax, group = id)) +
  geom_line(alpha = .2) +
  # create facets based on month
  facet_wrap(. ~ month) +
  theme(axis.text.x = element_text(
    angle = 90,
    vjust = 0.5,
    hjust = 1
  ),
  # remote legends
  legend.position = "none") +
  # add title and label
  labs(title = "Average max temperature for each station", y = "average max temperature")
```

    ## `summarise()` has grouped output by 'year', 'month'. You can override using the
    ## `.groups` argument.

    ## Warning: Removed 5640 row(s) containing missing values (geom_path).

<img src="p8105_hw3_yw4005_files/figure-gfm/avg max temp plot-1.png" width="90%" />

It seems like the average temperatures in July are all higher than those
in January across these years. Average temperatures in July seem to have
a lower variance than those in January. Also, it seems that for both
January and July, the average max temperatures has similar fluctuation
around the same years. There is one significant outlier in approximately
1988 July.

``` r
tmax_tmin_p <- clean_ny_noaa %>%
  # reformat data
  pivot_longer(
    cols = c("tmax", "tmin"),
    names_to = "temp_type",
    values_to = "temp_value"
  )  %>%
  # create boxplot
  ggplot(aes(x = temp_type, y = temp_value)) +
  geom_boxplot() +
  labs(title = "Max Temperature vs. Min Temperature",
       plot.title = element_text(size=8))


snowfall_p <- clean_ny_noaa %>%
  # filter data
  filter(snow < 100 & snow > 0) %>%
  # create ridge plot
  ggplot(aes(x = snow, y = year)) +
  geom_density_ridges(alpha = .3) +
  # move legend to the right
  theme(legend.position = "right") +
  # add title and label
  labs(title = "Distribution of snowfall",
       x = "snowfall",
       plot.title = element_text(size = 8))

tmax_tmin_p + snowfall_p
```

    ## Warning: Removed 2268778 rows containing non-finite values (stat_boxplot).

    ## Picking joint bandwidth of 3.76

<img src="p8105_hw3_yw4005_files/figure-gfm/temp and snowfall plot-1.png" width="100%" />
